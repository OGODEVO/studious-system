system:
  model: "minimax/minimax-m2.5"
  provider: "novita"
  temperature: 0.7
  context_window: 204800       # Total context size of the model
  max_output_tokens: 130100   # Minimax M2.5 max (131100) minus safety buffer

providers:
  novita:
    base_url: "https://api.novita.ai/openai"
    api_key: ""                                  # Set in .env as NOVITA_API_KEY
  openai:
    base_url: "https://api.openai.com/v1"
    api_key: ""                                  # Set in .env as OPENAI_API_KEY

browser:
  headless: true
  viewport:
    width: 1280
    height: 900
  timeout: 15000        # navigation timeout in ms
  user_agent: "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"

tools:
  extract_max_chars: 3000
  max_links: 30
  search_results: 8

memory:
  extraction_model: "gpt-5-mini"             # any OpenAI v1-compatible model
  extraction_base_url: ""                      # leave empty for OpenAI, or set e.g. "https://api.novita.ai/v3/openai"
  extraction_api_key: ""                       # leave empty to use OPENAI_API_KEY, or set a separate key
  extraction_temperature: 0.1
  extraction_max_tokens: 1024                  # max tokens for memory extraction responses
  extract_every_n_turns: 3                     # run episodic extraction every N turns
  # compaction_threshold is now derived from system.context_window * 0.7
  max_recent_episodes: 5                       # how many episodes to load at bootstrap

scheduler:
  enabled: true
  tick_seconds: 15
  reminders:
    - id: "daily-llc-followup"
      enabled: false
      interval_minutes: 120
      lane: "background"
      prompt: "Reminder: work the LLC setup task and report the next concrete step."
  heartbeat:
    enabled: true
    interval_minutes: 30
    prompt: "Heartbeat: check queue backlog, memory pressure, and blocked work. Report concise actionable next steps."
